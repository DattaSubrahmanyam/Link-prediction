from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot
start = time.time()

ss = StandardScaler()
train_x = ss.fit_transform(train_x)
test_x = ss.fit_transform(test_x)
lr = LogisticRegressionCV(fit_intercept=True, max_iter=100, multi_class='multinomial', Cs=np.logspace(-2, 2, 20),
                          cv=2, penalty="l2", solver="lbfgs", tol=0.01)
lr.fit(train_x, train_y.ravel())
pred_prob = lr.predict(test_x)


end = time.time()
print('Model training iteration time : ' + str(round(end - start, 1)) + 's') 

accuracy = accuracy_score(test_y.ravel(),pred_prob)

print("Accuracy of Logistic regression model is ",str(round(accuracy*100,1)),"%")

performance_val=roc_auc_score(test_y, pred_prob)
print("The AUC Score of Logistic regression classification model is :" ,str(round(performance_val,1)*100),"%")

# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(test_y))]

lr_probs = lr.predict_proba(test_x)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:, 1]

# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(test_y.ravel(), ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(test_y.ravel(), lr_probs)
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()
