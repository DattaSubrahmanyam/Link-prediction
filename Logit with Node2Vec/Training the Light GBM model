import lightgbm as lgb

train_data = lgb.Dataset(train_x, train_y.ravel())
test_data = lgb.Dataset(test_x, test_y.ravel())

# define parameters
parameters = {
    'objective': 'binary',
    'metric': 'auc',
    'is_unbalance': 'true',
    'feature_fraction': 0.5,
    'bagging_fraction': 0.5,
    'bagging_freq': 20,
    'num_threads' : 2,
    'seed' : 76
}

start=time.time()
# train lightGBM model
model = lgb.train(parameters,
                   train_data,
                   valid_sets=test_data,
                   num_boost_round=1000,
                   early_stopping_rounds=20)

stop=time.time()

lgbm_prob=model.predict(test_x)

print(lgbm_prob[0:5])
for i in range(0,252412):
    if lgbm_prob[i]>=.5:       # setting threshold to .5
       lgbm_prob[i]=1
    else:  
       lgbm_prob[i]=0

print(lgbm_prob[0:5])
accuracy_lgbm = accuracy_score(lgbm_prob,test_y.ravel())

print("Accuracy of LightGBM model is ", str(round(accuracy_lgbm*100,1)),"%")

performance_val=roc_auc_score(test_y, lgbm_prob)
print("The AUC Score of LightGBM model is :" ,str(round(performance_val,1)*100),"%")

# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(test_y))]

lgb_probs = model.predict(test_x)

# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(test_y.ravel(), ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(test_y.ravel(), lgb_probs)
# plot the roc curve for the model
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
pyplot.plot(lr_fpr, lr_tpr, marker='.', label='LightGBM')
# axis labels
pyplot.xlabel('False Positive Rate')
pyplot.ylabel('True Positive Rate')
# show the legend
pyplot.legend()
# show the plot
pyplot.show()
